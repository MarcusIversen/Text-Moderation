# Text-Moderation
Information: In a child-safe application environment, a set of laws have been made by the EU. These laws are set to provide safety for children when they are engaging a child safe online environment. Therefore all User Generated Content (UGC), must be moderated in parallel to the child safety rules. 

Problem definition: Up until now, UGC have been moderated manually by an external moderation company. The LEGO group has by now developed an AI to moderate UGC, which solves the issues of manual moderation, but it has not been implemented yet.  When generating content, you are as a user (child) allowed to insert text to your creation, but upon post, then it will manually be moderated by real life employees of the external moderation company.

Solution: A mocked system that auto-moderates text. When text is being written, it scans for inappropriate content before it's posted to the application. This time-saving solution prevents moderation costs, shortens time of moderation and therefore enhances user experience. Furthermore it takes a step into automised moderation for UGC in child-safe mobile applications.
